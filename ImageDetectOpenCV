import cv2
import numpy as np
from OpenGL.GL import *
from OpenGL.GLU import *
import glfw
import pywavefront  # Used to load .obj model
# Loading models
try:
    model1 = pywavefront.Wavefront(
        'C:/Users/DR.RLW/Desktop/study/UAL/Year 3/Image_Recognition/Model/Lowpoly_tree_sample.obj', collect_faces=True
    )  # model 1
    model2 = pywavefront.Wavefront(
        'C:/Users/DR.RLW/Desktop/study/UAL/Year 3/Image_Recognition/Model/Wolf.obj', collect_faces=True
    )  # model 2
except Exception as e:
    print(f"Failed to loas the model: {e}") # if the model cannot be load, then automatically exit the program
    exit()

# set the initial Rotation angle and the initial model (which is none)
rotation_angle = 0
model_displayed = None  # model_displayed shows the current model


def init_gl(width, height):
    """Initialize OpenGL"""
    glClearColor(0.0, 0.0, 0.0, 1.0)
    glEnable(GL_DEPTH_TEST)
    glViewport(0, 0, width, height)
    glMatrixMode(GL_PROJECTION)
    glLoadIdentity()
    gluPerspective(45, width / height, 0.1, 100.0)
    glMatrixMode(GL_MODELVIEW)

    # Light
    glEnable(GL_LIGHTING)  # enable light source
    glEnable(GL_LIGHT0)  # enable first light source
    glEnable(GL_COLOR_MATERIAL)  # active materials & color

    # light configuration
    light_position = [5.0, 5.0, -4.5, 1.0] 
    light_ambient = [0.2, 0.2, 0.2, 1.0]  
    light_diffuse = [0.8, 0.8, 0.8, 1.0]  
    light_specular = [1.0, 1.0, 1.0, 1.0]  

    glLightfv(GL_LIGHT0, GL_POSITION, light_position)
    glLightfv(GL_LIGHT0, GL_AMBIENT, light_ambient)
    glLightfv(GL_LIGHT0, GL_DIFFUSE, light_diffuse)
    glLightfv(GL_LIGHT0, GL_SPECULAR, light_specular)

    # material configuration
    mat_specular = [1.0, 1.0, 1.0, 1.0]  # reflection
    mat_shininess = [50.0]  # highlight
    glMaterialfv(GL_FRONT, GL_SPECULAR, mat_specular)
    glMaterialfv(GL_FRONT, GL_SHININESS, mat_shininess)

# the function used to draw 3d models
def draw_model(model, rotation_angle):
    """Drawing the models and importing the color"""
    glPushMatrix()
    glTranslatef(0.0, -1.0, 0.0)
    glRotatef(rotation_angle, 0, 1, 0)  # rotation Y
    glRotatef(rotation_angle * 0.5, 1, 0, 0)  # rotation X

    if model == model1:
        glScalef(0.1, 0.1, 0.1)  # adjust the size if the model is model 1
    else:
        glScalef(0.01, 0.01, 0.01)  # adjust the size if the model is model 2

    glBegin(GL_TRIANGLES) #constructed the models through vertexes, meshes, faces...
    for mesh in model.mesh_list:  
        for face in mesh.faces:  
            for vertex_i in face:  
                vertex = model.vertices[vertex_i]  # get the coordinates of each vertex
                glVertex3f(*vertex)  # set the vertex
    glEnd()

    glPopMatrix()

def check_pattern(detected_pattern):
    """Check if the pattern match with the database"""
    target_pattern1 = [1, 0, 0, 1, 0, 1, 1]
    target_pattern2 = [0, 1, 1, 0, 1, 1, 0]
    pattern_left = [0, 1, 0, 0, 1, 1, 0]
    pattern_right = [0, 0, 1, 0, 1, 1, 0]

    if detected_pattern == target_pattern1:
        return "pattern1"
    elif detected_pattern == target_pattern2:
        return "pattern2"
    elif detected_pattern == pattern_left:
        return "left"
    elif detected_pattern == pattern_right:
        return "right"
    return None


def detect_pattern(frame, gray):
    """detect the pattern and return the central point"""
    blurred = cv2.GaussianBlur(gray, (9, 9), 2)
    circles = cv2.HoughCircles(
        blurred,
        cv2.HOUGH_GRADIENT,
        dp=1,
        minDist=30,
        param1=20,
        param2=25,
        minRadius=30,
        maxRadius=60
    )
    detected_centers = []
    if circles is not None:
        circles = np.round(circles[0, :]).astype("int")
        for (x, y, r) in circles:
            roi = gray[y - r:y + r, x - r:x + r]
            if roi.size > 0:
                avg_intensity = np.mean(roi)
                color = "black" if avg_intensity < 100 else "white"
                detected_centers.append((x, y, color))
                
                # Draw circles and center point for better visualization to see whether the pattern is detected or not
                cv2.circle(frame, (x, y), r, (0, 255, 0), 4)
                cv2.circle(frame, (x, y), 2, (0, 0, 255), 3)
                
                # Display the color of the beads for the programmer to adjust parameters to ensure more accurate detection
                cv2.putText(
                    frame,
                    color,  # color of the text
                    (x + 10, y - 10),  
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.7,
                    (255, 255, 255),  
                    2,  # weight of the font
                    cv2.LINE_AA
                )
    return detected_centers


def get_detected_pattern(detected_centers):
    """generate the matrix of the detected pattern"""
    pattern = []
    
    detected_centers.sort(key=lambda x: x[1])  # Sorted by the y coordinate,make sure that it is processed from top to the bottom
    for (x, y, color) in detected_centers:
       
        if 50 <= y < 150:  # first row
            pattern.append(1 if color == "black" else 0)
        elif 150 <= y < 250:  # second row
            pattern.append(1 if color == "black" else 0)
        elif 250 <= y < 350:  # third row
            pattern.append(1 if color == "black" else 0)
        elif 350 <= y < 450:  # fourth row
            pattern.append(1 if color == "black" else 0)
        elif 450 <= y < 550:  # fifth row
            pattern.append(1 if color == "black" else 0)
    return pattern


# initialize GLFW and camera
if not glfw.init():
    raise Exception("GLFW initialization failed")

width, height = 1280, 960
window = glfw.create_window(width, height, "3D Rotating Model", None, None)
if not window:
    glfw.terminate()
    raise Exception("GLFW window creation failed")

glfw.make_context_current(window)
init_gl(width, height)

cap = cv2.VideoCapture(0)

global rotation_angle, model_displayed

while not glfw.window_should_close(window):
    ret, frame = cap.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    detected_centers = detect_pattern(frame, gray)
    detected_pattern = get_detected_pattern(detected_centers)

    # turn detected_pattern to string 
    pattern_str = "".join(str(cell) for cell in detected_pattern)

    # Add text on top of the picture
    cv2.putText(
        frame,                        # the detected picture
        f"Detected Pattern: {pattern_str}",  # text being displayed
        (10, 30),                     # starting position (x, y)
        cv2.FONT_HERSHEY_SIMPLEX,     # font
        0.7,                          # size of the font
        (255, 255, 255),              # color of the font
        2,                            # weight of the font
        cv2.LINE_AA                   # Anti-aliasing
    )

    # detect the pattern and control the model
    pattern_type = check_pattern(detected_pattern)
    if pattern_type == "pattern1":
        if model_displayed != "model1":
            model_displayed = "model1"
            rotation_angle = 0  # reset the rotation angle when initializing a new model
    elif pattern_type == "pattern2":
        if model_displayed != "model2":
            model_displayed = "model2"
            rotation_angle = 0  
    elif pattern_type == "left":
        rotation_angle -= 1  # -1 is turn left
    elif pattern_type == "right":
        rotation_angle += 1  # and this is turn right

    if model_displayed == "model1":
        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)
        glLoadIdentity()
        gluLookAt(0, 0, 5, 0, 0, 0, 0, 1, 0)
        draw_model(model1, rotation_angle)  # draw model 1
        glfw.swap_buffers(window)
    elif model_displayed == "model2":
        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)
        glLoadIdentity()
        gluLookAt(0, 0, 5, 0, 0, 0, 0, 1, 0)
        draw_model(model2, rotation_angle)  # model 2
        glfw.swap_buffers(window)

    # display the mirrored frame because the camera used in testing is the front camera, which is automatically mirrored when displayed. 
    cv2.imshow('Flipped Frame', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
glfw.terminate()
